# bot.py
"""
ImageBot - Ahmed Khan
Features: images (enhance, remove bg, cartoon, ascii, watermark, pdf, compress, bw, invert, rotate, sticker),
video (compress, to_gif, to_animated_sticker), AI image gen (Free Stable Diffusion), safe file handling, per-user session.
"""

import os
import uuid
import traceback
import logging
from functools import partial

import telebot
from telebot import types

import cv2
import numpy as np
from rembg import remove
from PIL import Image, ImageDraw, ImageFont, ImageOps

# Ø¥Ø¹Ø¯Ø§Ø¯ logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Optional video support
try:
    from moviepy.editor import VideoFileClip
    MOVIEPY_OK = True
except Exception:
    VideoFileClip = None
    MOVIEPY_OK = False

# Optional Stable Diffusion support
try:
    from diffusers import StableDiffusionPipeline
    import torch
    SD_AVAILABLE = True
except Exception:
    SD_AVAILABLE = False

# ----- Config via env -----
BOT_TOKEN = os.getenv("BOT_TOKEN")
if not BOT_TOKEN:
    raise SystemExit("ERROR: BOT_TOKEN environment variable not set. Ø¶Ø¹ ØªÙˆÙƒÙ† Ø§Ù„Ø¨ÙˆØª ÙÙŠ Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© BOT_TOKEN")

bot = telebot.TeleBot(BOT_TOKEN)

USER_TAG = "@AHMED_KHANA"
DEV_NOTE = " Ø§Ù„Ù…Ø·ÙˆØ±"

# per-user in-memory state
user_states = {}

# ---- Utilities ----
def tmpname(prefix="tmp", ext=""):
    return f"{prefix}_{uuid.uuid4().hex}{('.' + ext) if ext else ''}"

def safe_remove(path):
    try:
        if path and os.path.exists(path):
            os.remove(path)
    except:
        pass

def cleanup_prefix(prefixes=("tmp_", "out_")):
    for fn in os.listdir("."):
        if any(fn.startswith(p) for p in prefixes):
            safe_remove(fn)

def send_photo(chat_id, path, caption=None):
    with open(path, "rb") as f:
        bot.send_photo(chat_id, f, caption=caption)

def send_doc(chat_id, path, caption=None):
    with open(path, "rb") as f:
        bot.send_document(chat_id, f, caption=caption)

# ---- Stable Diffusion Image Generation ----
def generate_ai_image_free(prompt, out=None):
    if out is None:
        out = tmpname("out_ai", "png")
    
    try:
        if not SD_AVAILABLE:
            raise Exception("Ù…ÙƒØªØ¨Ø© Stable Diffusion ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. run: pip install diffusers transformers accelerate torch torchvision")
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø®ÙÙŠÙ ÙˆØ³Ø±ÙŠØ¹
        model_id = "OFA-Sys/small-stable-diffusion-v0"
        
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            safety_checker=None  # Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙØ­Øµ Ù„Ù„Ø³Ø±Ø¹Ø©
        )
        
        if torch.cuda.is_available():
            pipe = pipe.to("cuda")
            logger.info("Using GPU for image generation")
        else:
            logger.info("Using CPU for image generation (Ø³ÙŠÙƒÙˆÙ† Ø£Ø¨Ø·Ø£)")
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù…Ø¹Ù„Ù…Ø§Øª Ø³Ø±ÙŠØ¹Ø©
        image = pipe(
            prompt, 
            num_inference_steps=20,
            guidance_scale=7.5,
            width=512,
            height=512
        ).images[0]
        
        image.save(out)
        logger.info(f"Successfully generated image for prompt: {prompt}")
        return out
        
    except Exception as e:
        logger.error(f"Image generation failed: {str(e)}")
        raise Exception(f"ÙØ´Ù„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯: {str(e)}")

# ---- Ø¨Ø§Ù‚ÙŠ Ø¯ÙˆØ§Ù„ Ø§Ù„ØµÙˆØ± (Ù†ÙØ³Ù‡Ø§ ÙƒÙ…Ø§ ÙƒØ§Ù†Øª) ----
def enhance_image(image_path, out=None):
    if out is None:
        out = tmpname("out_enhanced", "jpg")
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError("Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©")
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
    enhanced = cv2.filter2D(img, -1, kernel)
    cv2.imwrite(out, enhanced)
    return out

def remove_bg_image(image_path, out=None):
    if out is None:
        out = tmpname("out_nobg", "png")
    with open(image_path, "rb") as f:
        data = f.read()
    result = remove(data)
    with open(out, "wb") as f:
        f.write(result)
    return out

# ... (Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø®Ø±Ù‰ ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±) ...

# ---- Save incoming files ----
def save_photo(msg):
    file_info = bot.get_file(msg.photo[-1].file_id)
    data = bot.download_file(file_info.file_path)
    fname = tmpname("tmp_img", "jpg")
    with open(fname, "wb") as f:
        f.write(data)
    return fname

def save_video(msg):
    file_info = bot.get_file(msg.video.file_id)
    data = bot.download_file(file_info.file_path)
    fname = tmpname("tmp_vid", "mp4")
    with open(fname, "wb") as f:
        f.write(data)
    return fname

# ---- UI ----
def keyboard():
    markup = types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)
    buttons = [
        types.KeyboardButton("ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©"),
        types.KeyboardButton("Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©"),
        types.KeyboardButton("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ÙƒØ±ØªÙˆÙ†ÙŠØ©"),
        types.KeyboardButton("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ASCII"),
        types.KeyboardButton("Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø© Ù…Ø§Ø¦ÙŠØ©"),
        types.KeyboardButton("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ PDF"),
        types.KeyboardButton("Ø¶ØºØ· Ø§Ù„ØµÙˆØ±Ø©"),
        types.KeyboardButton("Ø£Ø¨ÙŠØ¶ ÙˆØ£Ø³ÙˆØ¯"),
        types.KeyboardButton("Ø¹ÙƒØ³ Ø§Ù„Ø£Ù„ÙˆØ§Ù†"),
        types.KeyboardButton("ØªØ¯ÙˆÙŠØ± Ø§Ù„ØµÙˆØ±Ø©"),
        types.KeyboardButton("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…Ù„ØµÙ‚"),
        types.KeyboardButton("Ø¶ØºØ· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"),
        types.KeyboardButton("ØªØ­ÙˆÙŠÙ„ ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ GIF"),
        types.KeyboardButton("ØªØ­ÙˆÙŠÙ„ ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ Ù…Ù„ØµÙ‚ Ù…ØªØ­Ø±Ùƒ (webm)"),
        types.KeyboardButton("ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")  # ğŸ¤– Ù…ÙŠØ²Ø© Ø¬Ø¯ÙŠØ¯Ø©
    ]
    markup.add(*buttons)
    return markup

@bot.message_handler(commands=['start','help'])
def cmd_start(m):
    user_states.pop(m.from_user.id, None)
    start_text = f"""
ğŸ‘‹ Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø£Ù†Ø§ Ø¨ÙˆØª Ø£Ø­Ù…Ø¯ Ø®Ø§Ù†. 

ğŸ¨ **Ù…ÙŠØ²Ø§ØªÙŠ Ø§Ù„Ù…ØªØ§Ø­Ø©:**
â€¢ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ± ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
â€¢ ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ÙƒØ±ØªÙˆÙ† ÙˆASCII
â€¢ Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø© Ù…Ø§Ø¦ÙŠØ© ÙˆØ¶ØºØ· Ø§Ù„ØµÙˆØ±
â€¢ ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ PDF ÙˆÙ…Ù„ØµÙ‚Ø§Øª
â€¢ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ GIF
â€¢ ğŸ¤– **ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ù…Ø¬Ø§Ù†ÙŠ!)**

Ø£Ø±Ø³Ù„ ØµÙˆØ±Ø© Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ Ø«Ù… Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.
    """
    bot.reply_to(m, start_text, reply_markup=keyboard())

@bot.message_handler(content_types=['photo'])
def on_photo(m):
    try:
        fname = save_photo(m)
        uid = m.from_user.id
        st = user_states.setdefault(uid, {"images": [], "videos": [], "pending": None})
        st["images"].append(fname)
        bot.reply_to(m, f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© (#{len(st['images'])}). ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ø²ÙŠØ¯ Ø£Ùˆ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ù…Ù„ÙŠØ©.", reply_mup=keyboard())
    except Exception as e:
        bot.reply_to(m, f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©: {e}")

# ... (Ø¨Ù‚ÙŠØ© handlers ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ) ...

# ---- Main action handler ----
@bot.message_handler(func=lambda m: True)
def handle_action(m):
    uid = m.from_user.id
    st = user_states.get(uid)
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ±ÙŠØ¯ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± ÙˆÙ„Ù… ÙŠØ±Ø³Ù„ ÙˆØµÙ Ø¨Ø¹Ø¯
    if m.text.strip() == "ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ":
        bot.reply_to(m, "ğŸ”„ Ø£Ø±Ø³Ù„ ÙˆØµÙ (prompt) Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©:")
        user_states.setdefault(uid, {"images": [], "videos": [], "pending": "ai_generate"})
        return
        
    if not st or (not st["images"] and not st["videos"]):
        bot.reply_to(m, "âš ï¸ Ø£Ø±Ø³Ù„ ØµÙˆØ±Ø© Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ Ø£ÙˆÙ„Ø§Ù‹ Ø«Ù… Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.", reply_markup=keyboard())
        return

    action = m.text.strip()
    try:
        # ... (Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ) ...
        
        elif action == "ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ":
            # Ù‡Ø°Ù‡ Ù„Ù† ØªÙ†ÙØ° Ù„Ø£Ù†Ù†Ø§ Ù†ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§ ÙÙŠ Ø­Ø§Ù„Ø© pending
            pass

        else:
            bot.reply_to(m, "â“ Ø£Ù…Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ â€” Ø§Ø®ØªØ± Ù…Ù† Ø§Ù„Ø£Ø²Ø±Ø§Ø± Ø£Ùˆ Ø§ÙƒØªØ¨ /help.")
            return

        bot.send_message(m.chat.id, f"âœ… ØªÙ…Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©. Ø§Ù„Ù…Ø·ÙˆØ±: {USER_TAG}")
    except Exception as e:
        tb = traceback.format_exc()
        bot.reply_to(m, f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
        logger.error(f"Error in handle_action: {tb}")
    finally:
        # cleanup user's inputs and temporary outputs
        imgs = st.get("images", [])
        vids = st.get("videos", [])
        for p in imgs + vids:
            safe_remove(p)
        cleanup_prefix(prefixes=("tmp_", "out_"))
        user_states.pop(uid, None)

# ---- Handler for AI prompt ----
@bot.message_handler(func=lambda m: user_states.get(m.from_user.id, {}).get("pending") == "ai_generate")
def handle_ai_prompt(m):
    uid = m.from_user.id
    st = user_states.get(uid)
    
    if not st:
        return
        
    prompt = m.text.strip()
    try:
        bot.send_message(m.chat.id, "â³ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©... (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ 1-2 Ø¯Ù‚Ø§Ø¦Ù‚)")
        
        out_path = generate_ai_image_free(prompt)
        
        with open(out_path, 'rb') as photo:
            bot.send_photo(m.chat.id, photo, caption=f"ğŸ–¼ï¸ ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!\nØ§Ù„ÙˆØµÙ: {prompt}\n{USER_TAG}")
        
        safe_remove(out_path)
        logger.info(f"Successfully generated image for user {uid}")
        
    except Exception as e:
        error_msg = f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©: {str(e)}"
        bot.reply_to(m, error_msg)
        logger.error(f"AI generation failed for user {uid}: {str(e)}")
    
    finally:
        # Reset user state
        st["pending"] = None

if __name__ == "__main__":
    logger.info("ImageBot starting with Stable Diffusion support...")
    if SD_AVAILABLE:
        logger.info("Stable Diffusion is available!")
    else:
        logger.warning("Stable Diffusion not available. Install: pip install diffusers transformers accelerate torch torchvision")
    
    bot.infinity_polling()
